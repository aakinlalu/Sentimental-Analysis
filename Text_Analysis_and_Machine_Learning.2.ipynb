{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT ANALYSIS AND MACHINE LEARNING  Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before proceeding, please Check _\"Text Analysis and Machine learning Part 1\"_ if you have not read it. Click [Link](http://nbviewer.jupyter.org/github/aakinlalu/Sentimental-Analysis/blob/master/Sentimental_Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to classify positive and negative tweet labelled in the first part of the article. We will extract TF-IDF fetures from tweets using TF-IDF weights and clssify the tweets using Logistic Regression and GridSearchCV. The end goal is to check the performance of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag_of_words with TF-IDF (Term Frequency- Inverse Document Frequency) weights \n",
    "According to Gavin Hackeling(Mastering ML with Scikit-Learn), many words might appear with the same frequency in two documents but the documents could still be disimilar if one document is many time larger than the other. Scikit-Learn's TfidfTransformer object can mitigate this problem by transforming a matrix of term frequency vectors into a matrix of normalized term frequency weights.  \n",
    "\n",
    "The smoothed, **normalized term frequencies** are by the following equations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{eqnarray}\n",
       "{\\mathbf{t}}\\,  {\\mathbf{f}}{\\mathbf{(t,d)}} & = \\frac{{\\mathbf{f}}{\\mathbf{(t,d)}}\\, {\\mathbf{+}}\\, \n",
       "{\\mathbf{1}} }{\\mathbf{||x||}}\\\\\n",
       "\\end{eqnarray}"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Latex\n",
    "Latex(r\"\"\"\\begin{eqnarray}\n",
    "{\\mathbf{t}}\\,  {\\mathbf{f}}{\\mathbf{(t,d)}} & = \\frac{{\\mathbf{f}}{\\mathbf{(t,d)}}\\, {\\mathbf{+}}\\, \n",
    "{\\mathbf{1}} }{\\mathbf{||x||}}\\\\\n",
    "\\end{eqnarray}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f(t,d) is the frequency of term t in document d.\n",
    "||x|| is the L2 normalization of the count vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  **Inverse document frequency (IDF)** ia a measure of how rare or common a word is in a corpus. \n",
    "\n",
    "Scikit-learn provides a TfidfVectorizer class that wraps CountVectorizer and TfidfTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load and split dataset into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'Aliases.csv',\n",
       " 'Analysis.png',\n",
       " 'database.sqlite',\n",
       " 'EmailReceivers.csv',\n",
       " 'Emails.csv',\n",
       " 'hashes.txt',\n",
       " 'labelledTweet.csv',\n",
       " 'Persons.csv',\n",
       " 'SMS.csv',\n",
       " 'tweet.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.chdir('desktop/output')\n",
    "os.getcwd()\n",
    "os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('labelledTweet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>co jrpbjvmg z nie mehr wie es war von mariann...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brink nasti war co du ucxicd</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vladimir putin kremlinrussia e vladimir war f...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>civilwarboutiq civil war victorian stripe ros...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worcesternew woman charg caus death war veter...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet     Label\n",
       "0   co jrpbjvmg z nie mehr wie es war von mariann...  positive\n",
       "1                       brink nasti war co du ucxicd  positive\n",
       "2   vladimir putin kremlinrussia e vladimir war f...  positive\n",
       "3   civilwarboutiq civil war victorian stripe ros...  positive\n",
       "4   worcesternew woman charg caus death war veter...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_raw, x_test_raw, y_train, y_test = train_test_split(df['Tweet'], df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Vectorizer = TfidfVectorizer()\n",
    "x_train = Vectorizer.fit_transform(x_train_raw)\n",
    "x_test = Vectorizer.transform(x_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression to classify the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make prediction with Logistic Regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: positive Tweet:  war guilt grace m live proof gracewin everi time matthew west co ahkjqbi ha jesu love\n",
      "Predicted: positive Tweet:  icc investig russia georgia war co trqg aypzj\n",
      "Predicted: positive Tweet:  three isra kill jerusalem attack co hknfpi lk\n",
      "Predicted: positive Tweet:  co tvyclrz bm putin seek peac prepar war allpolit\n",
      "Predicted: positive Tweet:  march war face changelog hotfix thursday novemb th co jy nygn vu\n"
     ]
    }
   ],
   "source": [
    "for i, predict in enumerate(predicted[:5]):\n",
    "    print 'Predicted: %s Tweet: %s' % (predict, list(x_test_raw)[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the performance of the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy** measures a fraction of the classifier prediction that are correct.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97861540476814257"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "While accuracy measures the overall corrected of the classifier, it does not distinguish between false positive errors and false negative errors. ROC curve visualizes a classifier performance. ROC curve ilustrates the classifier's performance for all values of the decrimination threshold. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Precision** is the fraction of positive predictions that are correct.  \n",
    "**Recall** is the fraction of the truly positive instance that the classifier recognises.  \n",
    "**F1 measure** is the harmonic mean, or weighted average of the  precission and recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.89572321,  0.98467756]),\n",
       " array([ 0.81043478,  0.99231478]),\n",
       " array([ 0.85094727,  0.98848142]),\n",
       " array([ 2300, 28236]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_recall_fscore_support(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Tuning Models with Grid Search\n",
    "---\n",
    "Grid search is a common method to select the hyperparameter values that produce the best model. Grid search takes a set of possible values for each hyperparameter that should be tuned, and evaluates a model trained on each element of the cartesian product of the sets. The disadvantage of grid search is that it is computationally costly for even small sets of hyperparameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    pipeline = Pipeline([('vect', TfidfVectorizer(stop_words='english')),\n",
    "                        ('clf', LogisticRegression())])\n",
    "    parameters = {'vect__max_df': (0.25, 0.5, 0.75),\n",
    "                 'vect__stop_words': ('english', None),\n",
    "                 #'vect__max_features': (2500, 5000, 10000, None),\n",
    "                 'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "                 'vect__use_idf': (True, False),\n",
    "                 'vect__norm': ('l1', 'l2'),\n",
    "                 'clf__penalty': ('l1', 'l2'),\n",
    "                 'clf__C': (0.01, 0.1, 1, 10),}\n",
    "    grid_search = GridSearchCV(pipeline, parameters, n_jobs=3, verbose=1, scoring='accuracy', cv=3)\n",
    "    df = pd.read_csv('labelledTweet.csv')\n",
    "    X, y = df['Tweet'], df['Label']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print 'Best score: 0.3f' % grid_search.best_score_\n",
    "    print 'Best parameters set:'\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print '\\t%: %r' % (param_name, best_parameters[param_name])\n",
    "    predictions = grid_search.predict(X_test)\n",
    "    print 'Accuracy:', accuracy_score(y_test, predictions)\n",
    "    print 'Precision', precision_score(y_test, predictions)\n",
    "    print 'Recall', recall_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reference\n",
    "---\n",
    " Hackeling, G 2014, _Master Machine Learning with Scikit-learn_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
